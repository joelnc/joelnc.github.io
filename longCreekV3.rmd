---
title: "2005 Long Creek TMDL"
output:
    html_document:
        toc: true
        toc_float: true
        code_folding: hide
---
## Overview
This is an attempt to re-create the TSS/Turbidity analysis used in the
[2005 Long Creek TMDL Analysis](https://files.nc.gov/ncdeq/Water%20Quality/Planning/TMDL/FINAL%20TMDLS/Catawba/ApprovedLongCreekTurbidityTMDL.pdf).
It includes a walkthrough / re-creation of the data analysis tables and
figures in the original TMDL, with discrepencies noted where they
occur. The analysis is done using R, and specifically the RMarkdown
package to bundle the work into this interactive html document.

## Load Packages
```{R, eval=FALSE}

rm(list=ls())

## Load Packages
pks <- c("dplyr", "dataRetrieval", "rmarkdown",
         "plotly", "DT", "broom", "viridis")
lapply(pks, library, character.only=TRUE)

```

## Load State Data
These data were copied and pasted out of the TMDL appendix.  Then
reformatted into csv format, imported with R, date interpreted to
include date and POSIXt objects, and saved as an .rds object.
```{R}
## Load in data extracted from 2005 TMDL appendix
stateData <- readRDS("C:/users/joel/Documents/R/Long-Creek/stateData.rds")
print(stateData)

```
## Get USGS Data
Use the dataRetrieval package to get historical daily flow data
for City/County site MC10.

```{R, chunk1}
usgsFlow <- readNWISdv(siteNumbers="02142900", parameterCd="00060",
                       startDate="1970-01-01", endDate="2004-09-08")
usgsFlow <- usgsFlow[,3:4]
names(usgsFlow) <- c("dt.DATE", "cfs")

head(usgsFlow,10)
```

-----

## Merge Flow Rates With State Data
Attach the daily flow rates from the previous step to the water
quality dataset extracted from the TMDL Appendix.

```{R, chunk2}
stateData <- merge(stateData, usgsFlow, by="dt.DATE", all.x=TRUE, all.y=FALSE)

head(stateData)

```

-----

## Plot Timeseries (TMDL Fig. 15)
Recreate Figure 15, a time series of daily flow rates plotted along
with the TSS and Turbidity sample concentrations used in the TMDL, and
a 50 NTU reference line.

```{R, chunk3}
## subset flow for plotting
flow <- usgsFlow %>%
    filter(dt.DATE > "1997-01-01",
           dt.DATE < "2004-05-01")

plot1 <- plot_ly() %>%
    add_trace(data=flow, x=~dt.DATE, y=~cfs,
              type="scatter", mode="lines", name="Flow",
              yaxis="y2") %>%
    add_markers(data=stateData, x=~dt.DATE, y=~tss,
                type="scatter", mode="markers", name="TSS") %>%
    add_markers(data=stateData, x=~dt.DATE, y=~turbidity,
                type="scatter", mode="markers", name="Turbidity") %>%
    add_trace(x=c(min(stateData$dt.DATE), max(stateData$dt.DATE)),
                y=c(50,50), type="scatter", mode="lines", name="Standard") %>%
    layout(yaxis=list(title="TSS or Turbidity",
                      xaxis=list(title="Date"),
                      range=c(0,500)),
           yaxis2=list(overlaying = "y", side = "right",
                       title = "Flow (cfs)",
                       showgrid=FALSE, range=c(0,1200)),
           legend=list(x=.2, y=100, orientation='h'))


plot1

```

-----

## Turbidity Exceedances Table (TMDL Table 5)
Here we see a slight difference.  The TMDL Table 5 counts 21 "moist"
samples and 16 "mid-range".  My accounting has 23 "moist" samples and
14 "mid-range".  It is possible that USGS updated historical records
in some way since the State did their analysis; possible the State did
something wrong; possible I did something wrong.  Not really a big
deal as  the distinction between moist and mid doesn't have much regulatory
importance.

```{R}
## Verbose function to create Table 5
returnExcursionsState <- function(chem, flow) {

    high <- c(90, unname(quantile(flow$cfs, 0.90)),
              nrow(chem %>% filter(cfs>unname(quantile(flow$cfs, 0.90)))),
              nrow(chem %>% filter(cfs>unname(quantile(flow$cfs, 0.90)),
                                   turbidity>50))
              )

    moist <- c(60, unname(quantile(flow$cfs, 0.60)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.90)),
                                   cfs>unname(quantile(flow$cfs, 0.60)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.90)),
                                   cfs>unname(quantile(flow$cfs, 0.60)),
                                   turbidity>50))
              )

    mid <- c(40, unname(quantile(flow$cfs, 0.40)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.60)),
                                   cfs>unname(quantile(flow$cfs, 0.40)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.60)),
                                   cfs>unname(quantile(flow$cfs, 0.40)),
                                   turbidity>50))
              )

    dry <- c(5, unname(quantile(flow$cfs, 0.05)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.40)),
                                   cfs>unname(quantile(flow$cfs, 0.05)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.40)),
                                   cfs>unname(quantile(flow$cfs, 0.05)),
                                   turbidity>50))
              )
    low <- c(0,
             unname(quantile(flow$cfs, 0.0)),
             nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.05)))),
             nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.05)),
                                   turbidity>50))
              )

    returnTable <- as.data.frame(rbind(high, moist, mid, dry, low))
    names(returnTable) <- c("Percentile","Flow Rate","# Samples","# Exc.")
    returnTable
}

DT::datatable(returnExcursionsState(chem=stateData, flow=usgsFlow),
              options=list(dom='t'))

```

-----

## TSS Turbidity Regression (TMDL Fig 16)
Since the State had many turbidity samples without matching TSS, and
wanted to base the TMDL on TSS, they developed this relationship.  I'm
able to recreate this relationship exactly using the `lm` function on
untransformed data.  So far so good.

```{R}
plot2 <- plot_ly() %>%
    add_markers(data=stateData, x=~turbidity, y=~tss,
                type="scatter", mode="markers",) %>%
    layout(yaxis=list(title="TSS (mg/L)"), xaxis=list(title="Turbidity (NTU)"))

lm1 <- lm(tss~turbidity, data=stateData)

plot2 <- add_trace(plot2, x=lm1$model[["turbidity"]][order(lm1$model[["turbidity"]])],
                   y=lm1$fitted[order(lm1$model[["turbidity"]])],
                   type="scatter", mode="lines", name="Lin. Regr.")

plot2

td <- tidy(lm1); gl <- glance(lm1)
print(paste0("Equation is: TSS = ", format(td$estimate[2], digits=3),
             " * TURB + ", format(td$estimate[1], digits=3),
             " .  R Squared = ", format(gl$r.squared, digits=3),
             " .  Given this regression, the 50 NTU standards equates to ",
             format(td$estimate[2]*50+td$estimate[1], digits=4), " mg/L TSS.")
      )

```

**BUT, weird that this dataset suggests 50 NTU is equivalent to 17
mg/L TSS.  Quick analysis of most of our data sets put that number at
~45 mg/L TSS.**

-----

## Load Duration Curve (TMDL Fig 17)
Next, the Figure 17 load duration curve is simply the flow duration
curve multiplied by a concentration to turn it into a load.  So first
take the long term daily flow record from USGS and construct a FDC in
the usual way.

Next, figure out what to multiply by.  For the explicit 10% MOS in
this TMDL, they say we need to be under 45 NTU.  Using the regression
equation from above, that is equated with 15.72 mg/L TSS.  So below,
column fdcData$load45 is the FDC (first term) multiplied by the 15.72
TSS conc (last term), multiplied by some unit conversions (middle) to
get into lbs/day.  That covers the line.

For the sample points, each sample concentration needs to be converted
to a load (lbs/day, y axis) and assigned an exceedance probability ("qi",
x-axis) based on the corresponding flow rate.  So for the TSS samples,
multiply concentrations by that day's flow and convert units to get
lbs for that day.  Then, following the 'merge' with the FDC data,
every sample's flow rate will already be matched with its 'qi'. So we
have what we need to scatter plot TSS over the LDC.

For Turbidity samples with no matching TSS, first predict TSS via the
previously developed regression equation.  Then use the same approach
to calculate lbs/day and scatter plot those samples.

Lastly, create the ldcData$allTSS column by combining the TSS and
Turbidity based daily loads into a single data set for plotting and
subsequent regression (but not used in this figure).

```{R}
## FDC prep calcs
fdcData <- usgsFlow
fdcData <- fdcData[order(fdcData$cfs, decreasing=FALSE), ]
fdcData$rank <- seq(1,nrow(fdcData))
fdcData$qi <- (1-(fdcData$rank/(nrow(fdcData)+1)))*100
fdcData$load45 <- fdcData$cfs*(60*60*24)*(28.32)*(1/(1000*453.59))*15.72

## Make a new df copy to work with
ldcData <- stateData

## Attach longterm qi to each sample date
ldcData <- merge(ldcData, fdcData[,c("dt.DATE", "qi")],
                 by="dt.DATE", all.x=TRUE, all.y=FALSE)

## New col for TSS predicted from Turb
ldcData$predTSS <- rep(NA, nrow(ldcData))
ldcData$predTSS[which(is.na(ldcData$tss))] <-
    (td$estimate[2]*ldcData$turbidity[which(is.na(ldcData$tss))]+td$estimate[1])

## Combine actual and estimated TSS into one single col (for later..)
ldcData$allTSS <- rowSums(ldcData[, c("tss", "predTSS")], na.rm=TRUE)

## Compute estimate daily loads by flow * conc * unit conversion
ldcData$Turb2Load <- ldcData$cfs*(60*60*24)*(28.32)*(1/(1000*453.59))*ldcData$predTSS
ldcData$TSS2Load <- ldcData$cfs*(60*60*24)*(28.32)*(1/(1000*453.59))*ldcData$tss

## Plotting
plot3 <- plot_ly() %>%
    add_trace(data=fdcData, x=~qi, y=~load45,
              type="scatter", mode="lines",
              name="45 NTU Limit Curve") %>%
    add_trace(data=ldcData, x=~qi, y=~Turb2Load,
              type="scatter", mode="markers",
              name="Turb Est.") %>%
    add_trace(data=ldcData, x=~qi, y=~TSS2Load,
              type="scatter", mode="markers",
              name="TSS Obs.") %>%
    layout(yaxis=list(type="log", title="Load (lbs/day)"),
           legend=list(orientation="h", x=50, y=.95))

plot3

```

-----

## TSS Excursions (TMDL Table 6)
Below is a re-creation of TMDL Table 6.  Note, the State only counts 12 exceedances but
I get 15.  This is curious.
```{R}
returnTSSExcursions1 <- function(chem, flow, thresh) {

    high <- c(90, unname(quantile(flow$cfs, 0.90)),
              nrow(chem %>% filter(cfs>unname(quantile(flow$cfs, 0.90)))),
              nrow(chem %>% filter(cfs>unname(quantile(flow$cfs, 0.90)),
                                   allTSS>thresh))
              )

    moist <- c(60, unname(quantile(flow$cfs, 0.60)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.90)),
                                   cfs>unname(quantile(flow$cfs, 0.60)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.90)),
                                   cfs>unname(quantile(flow$cfs, 0.60)),
                                   allTSS>thresh))
              )

    mid <- c(40, unname(quantile(flow$cfs, 0.40)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.60)),
                                   cfs>unname(quantile(flow$cfs, 0.40)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.60)),
                                   cfs>unname(quantile(flow$cfs, 0.40)),
                                   allTSS>thresh))
              )

    dry <- c(5, unname(quantile(flow$cfs, 0.05)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.40)),
                                   cfs>unname(quantile(flow$cfs, 0.05)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.40)),
                                   cfs>unname(quantile(flow$cfs, 0.05)),
                                   allTSS>thresh))
              )
    low <- c(0, unname(quantile(flow$cfs, 0.0)),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.05)))),
              nrow(chem %>% filter(cfs<=unname(quantile(flow$cfs, 0.05)),
                                   allTSS>thresh))
              )

    returnTable <- as.data.frame(rbind(high, moist, mid, dry, low))
    names(returnTable) <- c("Percentile", "Flow Rate", "# Samples", "# Exc.")
    returnTable
}


DT::datatable(returnTSSExcursions1(chem=ldcData[,c("dt.DATE","allTSS","cfs")],
                                   flow=usgsFlow, thresh=17.22),
              options=list(dom='t'))

```
....

**Looking at the high flow range**, the data for the 4 high flow
samples are printed below. In TMDL Table 5, it was noted that for the
4 highest flow samples, all 4 were 50 NTU exceedances.  Table 6 from
the  TMDL tells us that only 1 of those 4 exceeded 17 mg/L TSS.  This
does not appear to match up with the data set.

```{r}
print(tail(stateData[order(stateData$cfs),], 4))
```

-----

## TMDL Table 7
This is just a monthly summary of the number of NTU violations in the
period of analysis, as presented in the TMDL.  Things match up fine.


```{r}
returnTSSExcursions2 <- function(chem, flow, thresh) {

    chem <- chem %>%
        filter(turbidity>thresh) %>%
        mutate(Mon = months(dt.DATE))

    monthlyTable <- data.frame(Jan=length(which(chem$Mon=="January")),
                               Feb=length(which(chem$Mon=="February")),
                               Mar=length(which(chem$Mon=="March")),
                               Apr=length(which(chem$Mon=="April")),
                               May=length(which(chem$Mon=="May")),
                               Jun=length(which(chem$Mon=="June")),
                               Jul=length(which(chem$Mon=="July")),
                               Aug=length(which(chem$Mon=="August")),
                               Sep=length(which(chem$Mon=="September")),
                               Oct=length(which(chem$Mon=="October")),
                               Nov=length(which(chem$Mon=="November")),
                               Dec=length(which(chem$Mon=="December")),
                               row.names="Exceedances")

    monthlyTable
}

DT::datatable(returnTSSExcursions2(chem=ldcData[,c("dt.DATE","turbidity","cfs")],
                                   flow=usgsFlow, thresh=50),
              options=list(dom='t'))

```

-----

## Figure 18
Here is where things diverge.

TMDL Figure 18 takes the untransformed data and plots it in
excel on a log y axis.  Then an exponential curve is fit and plotted
to produce the figure.  In contrast, the statistical analysis in
Appendix H of the TMDL fits a linear model to the ln transformed data.
These approaches are basically equivalent, except for differences in
curve fitting algorithms between programs (if different programs were
used...).

I'm able to follow the procedure (I think) but am arriving at a
different result.

Step 1 is to fit a regression to ln transformed loads.  That is
`lm2` below.  The subsetting step (`[5:76]`) drops the highest 10% and lowest
5% of flows.  Then I use `predict` to get the loads predicted by the model
and the prediction interval.  They appear to be basing things off an 80th
percentile line, which is the same as a 60% PI upper bound under a two
tailed approach.

The bias correction calcs are based off of the approach presented
in Appendix H, and also use the nonparametric smearing approach of
Duan (1983); mean prediction objects `biasCorrFit` and `smearFit`,
respectively.  The subsequent `...Upper` terms are the same
corrections applied to the upper CI from regression fit.

The main issue I'm seeing is that my regression is steeper than what the
State produced, even after dropping the highest 10% and lowest 5% of
flows. It also does not appear that TMDL Figure 18 is using the bias
corrected results, as my uncorrected fit appears to thread the sample
points near equivalently to the fit shown in TMDL Figure 18.


```{R}
## LDC prep
ldcData <- ldcData[order(ldcData$qi),]

## Combined tss turb load data col
ldcData$allLoad <- rowSums(ldcData[, c("TSS2Load", "Turb2Load")], na.rm=TRUE)

## Regression
lm2 <- lm(log(allLoad)~qi, data=ldcData[5:76,])
newx <- data.frame(qi=c(95, 10))
pred2 <- predict(lm2, newdata=newx, interval="prediction", level=0.60)
preddf2 <- as.data.frame(pred2)

## Create summary object and compute bias adjustments
sm2 <- summary(lm2)
biasCorrFit <- exp(preddf2$fit+(mean(sm2$residuals^2)/2))
smearFit <- exp(preddf2$fit)*(1/length(sm2$residuals))*sum(exp(sm2$residuals))
biasCorrUpper <- exp(preddf2$upr+(mean(sm2$residuals^2)/2))
smearUpper <- exp(preddf2$upr)*(1/length(sm2$residuals))*sum(exp(sm2$residuals))

plot5 <- plot_ly() %>%
    ## Plot 45 NTU Limit Curve
    add_trace(data=fdcData, x=~qi, y=~load45,
              type="scatter", mode="lines",
              name="45 NTU Limit Curve",
              line=list(color=viridis(8)[1])) %>%

    ## Plot sample sets, TSS, Turb, Combined
    add_trace(data=ldcData, x=~qi, y=~Turb2Load,
              type="scatter", mode="markers",
              name="Turb Pred.") %>%
    add_trace(data=ldcData, x=~qi, y=~TSS2Load,
              type="scatter", mode="markers",
              name="TSS") %>%

    ## Plot fit line and crack at bias corrected fit line
    add_trace(x=newx$qi, y=exp(preddf2$fit),
              type="scatter", mode="lines", name="Fit",
              line = list(color = 'rgb(0, 0, 0)')) %>%
    add_trace(x=newx$qi, y=biasCorrFit,
              type="scatter", mode="lines", name="Bias Corrected Fit TMDL",
              line = list(color = viridis(8)[6])) %>%
    add_trace(x=newx$qi, y=smearFit,
              type="scatter", mode="lines", name="Bias Corrected Fit Smearing",
              line = list(color = "red")) %>%

    ## Plot upper PI
    add_trace(x=c(95, 10), y=exp(preddf2$upr), type="scatter",
              mode="lines", name="Upper PI",
              line = list(color = 'rgb(0, 0, 0)', width = 2, dash = 'dot')) %>%
    add_trace(x=c(95, 10), y=biasCorrUpper, type="scatter",
              mode="lines", name="Bias Corrected Upper PI",
              line = list(color = viridis(8)[6], width = 2, dash = 'dot')) %>%
    add_trace(x=c(95, 10), y=smearUpper,
              type="scatter",
              mode="lines", name="Bias Corrected Smear Upper PI",
              line = list(color = "red", width = 2, dash = 'dot')) %>%


    ## Background line .. reg fit to subset of data below the load45 (or 50)
    add_trace(x=c(95, 10), y=exp(preddf2$lwr), type="scatter",
              mode="lines", name="Lower PI",
              line = list(color = 'rgb(0, 0, 0)', width = 2, dash = 'dot')) %>%


    ## Vert Grid
    add_trace(x=c(10, 10), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%
    add_trace(x=c(40, 40), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%
    add_trace(x=c(60, 60), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%
    add_trace(x=c(95, 95), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%

    ## Horiz grid
    add_trace(x=c(0, 100), y=c(10, 10), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(100, 100), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(1000, 1000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(10000, 10000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(100000, 100000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%


    layout(yaxis=list(type="log", showgrid=FALSE, range=c(log(2),log(200))),
           xaxis=list(tick0=0, dtick=10, showgrid=FALSE),
           legend=list(x=.1, y=100, orientation='h'))

plot5

```

-----

## Appendix I Background Figure

```{R}
## LDC prep
ldcBack <- ldcData[order(ldcData$qi),]
ldcBack <- select(ldcBack, "qi", "cfs", "Turb2Load", "TSS2Load")
ldcBack$qiR <- round(ldcBack$qi, digits=2)

## Round adn subset FDC df
fdcData$qiR <- round(fdcData$qi, digits=2)
fdcBack <- select(fdcData, "cfs", "qiR", "load45")
fdcBack <- fdcBack[which(!duplicated(fdcBack$qiR)),]

## Merge and collapse dfs
backData <- merge(ldcBack, fdcBack, by="qiR",
                  all.x=TRUE, all.y=FALSE)
backData$allLoad <- rowSums(backData[, c("TSS2Load", "Turb2Load")], na.rm=TRUE)


## Regression of data points less than WQS curve
lm3 <- lm(log(allLoad)~qi, data=backData[which(backData$allLoad<backData$load45),])
newx <- data.frame(qi=c(95, 10)) ## predict over the 95 / 10 range
pred3 <- predict(lm3, newdata=newx, interval="prediction", level=0.60)
preddf3 <- as.data.frame(pred3)

## Bias corrected fit
sm3 <- summary(lm3)
biasCorrBackFit <- exp(preddf3$fit+(mean(sm3$residuals^2)/2))

## To do a bias corrected prediction of the median backgound load
newnewx <- data.frame(qi=c(50))
pred4 <- predict(lm3, newdata=newnewx, interval="prediction", level=0.60)
exp(pred4[1]+(mean(sm3$residuals^2)/2))

## Need a few more steps to get back to the bias corrected estimates of background conc.
plot6 <- plot_ly() %>%
    ## Plot 45 NTU Limit Curve
    add_trace(data=backData, x=~qiR, y=~load45,
              type="scatter", mode="lines",
              name="45 NTU Limit Curve",
              line=list(color=viridis(8)[1])) %>%

    ## Plot sample sets, TSS, Turb, Combined
    add_trace(data=backData, x=~qi, y=~Turb2Load,
              type="scatter", mode="markers",
              name="Turb Pred.") %>%
    add_trace(data=backData, x=~qi, y=~TSS2Load,
              type="scatter", mode="markers",
              name="TSS") %>%
    add_trace(data=backData[which(backData$allLoad<backData$load45),],
              x=~qi, y=~allLoad,
              type="scatter", mode="markers",
              name="All Less than Thresh.") %>%

    ## Plot fit line and crack at bias corrected fit line
    add_trace(x=newx$qi, y=exp(preddf3$fit),
              type="scatter", mode="lines", name="Fit",
              line = list(color = 'rgb(0, 0, 0)')) %>%
    ## add_trace(x=newx$qi, y=biasCorrFit,
    ##           type="scatter", mode="lines", name="Bias Corrected Fit TMDL",
    ##           line = list(color = viridis(8)[6])) %>%
    ## add_trace(x=newx$qi, y=smearFit,
    ##           type="scatter", mode="lines", name="Bias Corrected Fit Smearing",
    ##           line = list(color = "red")) %>%

    ## ## Plot upper PI
    ## add_trace(x=c(95, 10), y=exp(preddf2$upr), type="scatter",
    ##           mode="lines", name="Upper PI",
    ##           line = list(color = 'rgb(0, 0, 0)', width = 2, dash = 'dot')) %>%
    ## add_trace(x=c(95, 10), y=biasCorrUpper, type="scatter",
    ##           mode="lines", name="Bias Corrected Upper PI",
    ##           line = list(color = viridis(8)[6], width = 2, dash = 'dot')) %>%
    ## add_trace(x=c(95, 10), y=smearUpper,
    ##           type="scatter",
    ##           mode="lines", name="Bias Corrected Smear Upper PI",
    ##           line = list(color = "red", width = 2, dash = 'dot')) %>%


    ## ## Background line .. reg fit to subset of data below the load45 (or 50)
    ## add_trace(x=c(95, 10), y=exp(preddf2$lwr), type="scatter",
    ##           mode="lines", name="Lower PI",
    ##           line = list(color = 'rgb(0, 0, 0)', width = 2, dash = 'dot')) %>%


    ## Vert Grid
    add_trace(x=c(10, 10), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%
    add_trace(x=c(40, 40), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%
    add_trace(x=c(60, 60), y=c(2, 200000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%
    add_trace(x=c(95, 95), y=c(2, 200000), type="scatter",
               mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1, dash = 'dash')) %>%

    ## Horiz grid
    add_trace(x=c(0, 100), y=c(10, 10), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(100, 100), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(1000, 1000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(10000, 10000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%
    add_trace(x=c(0, 100), y=c(100000, 100000), type="scatter",
              mode="lines", showlegend=FALSE,
              line = list(color = "grey", width = 1)) %>%


    layout(yaxis=list(type="log", showgrid=FALSE, range=c(log(2),log(200))),
           xaxis=list(tick0=0, dtick=10, showgrid=FALSE),
           legend=list(x=.1, y=100, orientation='h'))

plot6


td3 <- tidy(lm3); gl3 <- glance(lm3)
print(paste0("Equation is: Background Load = ", format(td3$estimate[2], digits=3),
             " * Qi + ", format(td3$estimate[1], digits=3),
             " .  R Squared = ", format(gl3$r.squared, digits=3),
             " .  Given this regression, the median flow background load equates to ",
             format(td3$estimate[2]*50+td3$estimate[1], digits=4), " lb/D TSS.")
      )




predCI <- predict(lm2, newdata=newx, interval="confidence", level=0.60)
preddfCI <- as.data.frame(predCI)

## Create summary object and compute bias adjustments
sm2 <- summary(lm2)
biasCorrFit <- exp(preddf2$fit+(mean(sm2$residuals^2)/2))
smearFit <- exp(preddf2$fit)*(1/length(sm2$residuals))*sum(exp(sm2$residuals))
biasCorrUpper <- exp(preddf2$upr+(mean(sm2$residuals^2)/2))
smearUpper <- exp(preddf2$upr)*(1/length(sm2$residuals))*sum(exp(sm2$residuals))



```

-----

## TMDL Table 8

Since the assimilative capacity / load allocation follows directly
from the analysis in this figure, I am wondering about the nature of
the discrepencies between the TMDL and the analysis contained herein.

```{R}
## Regression

## Re-predict full series rather than just hte 2 pts for plotting
newx <- data.frame(qi=seq(0.010, 100, by=0.010))
pred2 <- predict(lm2, newdata=newx, interval="prediction", level=0.60)
preddf2 <- as.data.frame(pred2)

biasCorrUpper <- exp(preddf2$upr+(mean(sm2$residuals^2)/2))
smearUpper <- exp(preddf2$upr)*(1/length(sm2$residuals))*sum(exp(sm2$residuals))

## Put all up PIs in a single DF
piDf <- cbind(newx, preddf2, biasCorrUpper, smearUpper)
piDf$upr <- exp(piDf$upr)

## Attach load45s
fdcDataReduced <- fdcData[,c("qiR", "load45", "cfs")]

piDf2 <- merge(piDf, fdcDataReduced, by.x="qi", by.y="qiR", all.x=TRUE,
               all.y=FALSE)
piDf2 <- piDf2[which(!is.na(piDf2$load45)),]


## Funciton to subset and compute load reduction reqs as f(critical)
reductionReqs <- function(dataFrame) {

    names(dataFrame) <- c("qi", "load45", "upr", "cfs")

    d <- dataFrame %>%
        filter(qi <= 10) %>%
        mutate(critDs=upr-load45) %>%
        slice(which.max(critDs))

    high <- c(d$cfs, d$qi, d$load45, d$upr,
              ((d$upr-d$load45)/d$upr)*100)

    d <- dataFrame %>%
        filter(qi <= 40, qi > 10) %>%
        mutate(critDs=upr-load45) %>%
        slice(which.max(critDs))

    moist <- c(d$cfs, d$qi, d$load45, d$upr,
              ((d$upr-d$load45)/d$upr)*100)

    d <- dataFrame %>%
        filter(qi <= 60, qi >40) %>%
        mutate(critDs=upr-load45) %>%
        slice(which.max(critDs))

    mid <- c(d$cfs, d$qi, d$load45, d$upr,
              ((d$upr-d$load45)/d$upr)*100)

    d <- dataFrame %>%
        filter(qi <= 95, qi> 60) %>%
        mutate(critDs=upr-load45) %>%
        slice(which.max(critDs))

    dry <- c(d$cfs, d$qi, d$load45, d$upr,
              ((d$upr-d$load45)/d$upr)*100)

    d <- dataFrame %>%
        filter(qi > 95) %>%
        mutate(critDs=upr-load45) %>%
        slice(which.max(critDs))

    low <- c(d$cfs, d$qi, d$load45, d$upr,
              ((d$upr-d$load45)/d$upr)*100)


    returnTable <- as.data.frame(rbind(high, moist, mid, dry, low))
    names(returnTable) <- c("Flow", "Crit. Flow", "Target", "80% PI", "Req. Red.")
    returnTable

}

DT::datatable(reductionReqs(dataFrame=piDf2[,c("qi","load45", "upr", "cfs")]),
              options=list(dom='t'))

```

-----
